import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import sys

# Cargar el DataFrame del Titanic
df = pd.read_csv('Titanic-Dataset.csv')

print("DataFrame Original - Primeras 5 filas:")
print(df.head())

print("\n--- Informaci√≥n del Dataset ---")
print(f"Dimensiones: {df.shape[0]} filas, {df.shape[1]} columnas")
print(f"\nColumnas: {df.columns.tolist()}")

print("\n--- Media (Promedio) de Variables Num√©ricas ---")

# Media de la columna 'Age'
media_age = df['Age'].mean()
print(f"Media de Edad: {media_age:.2f} a√±os")

# Media de la columna 'Fare'
media_fare = df['Fare'].mean()
print(f"Media de Tarifa: {media_fare:.2f}")

# Media de la columna 'SibSp' (Hermanos/C√≥nyuges a bordo)
media_sibsp = df['SibSp'].mean()
print(f"Media de Hermanos/C√≥nyuges: {media_sibsp:.2f}")

# Media de la columna 'Parch' (Padres/Hijos a bordo)
media_parch = df['Parch'].mean()
print(f"Media de Padres/Hijos: {media_parch:.2f}")

# Tambi√©n puedes calcular la media de todas las columnas num√©ricas a la vez
media_todas = df[['Age', 'Fare', 'SibSp', 'Parch']].mean()
print("\nMedia de todas las variables num√©ricas:")
print(media_todas)

print("\n--- Mediana de Variables Num√©ricas ---")

# Mediana de la columna 'Age'
mediana_age = df['Age'].median()
print(f"Mediana de Edad: {mediana_age:.2f} a√±os")

# Mediana de la columna 'Fare'
mediana_fare = df['Fare'].median()
print(f"Mediana de Tarifa: {mediana_fare:.2f}")

# Mediana de la columna 'Pclass'
mediana_pclass = df['Pclass'].median()
print(f"Mediana de Clase: {mediana_pclass:.2f}")

# Tambi√©n puedes calcular la mediana de todas las columnas num√©ricas a la vez
mediana_todas = df[['Age', 'Fare', 'SibSp', 'Parch', 'Pclass']].median()
print("\nMediana de todas las variables num√©ricas:")
print(mediana_todas)

print("\n--- Moda de Variables Categ√≥ricas y Num√©ricas ---")

# Moda de la columna 'Survived'
moda_survived = df['Survived'].mode()
print(f"Moda de Supervivencia: {moda_survived.tolist()} (0=No sobrevivi√≥, 1=Sobrevivi√≥)")

# Moda de la columna 'Pclass'
moda_pclass = df['Pclass'].mode()
print(f"Moda de Clase: {moda_pclass.tolist()}")

# Moda de la columna 'Sex'
moda_sex = df['Sex'].mode()
print(f"Moda de G√©nero: {moda_sex.tolist()}")

# Moda de la columna 'Embarked'
moda_embarked = df['Embarked'].mode()
print(f"Moda de Puerto de Embarque: {moda_embarked.tolist()} (C=Cherbourg, Q=Queenstown, S=Southampton)")

# Moda de la columna 'SibSp'
moda_sibsp = df['SibSp'].mode()
print(f"Moda de Hermanos/C√≥nyuges: {moda_sibsp.tolist()}")

print("\n--- Estad√≠sticas Adicionales ---")
print(f"Tasa de Supervivencia: {df['Survived'].mean():.2%}")
print(f"Distribuci√≥n por G√©nero:")
print(df['Sex'].value_counts())

# --- Calcular Q1, Q3 y el IQR para identificar outliers (usando Age) ---


# Nota: La columna 'Age' tiene valores nulos, los eliminamos para este an√°lisis
df_age = df['Age'].dropna()

print("\n--- An√°lisis de Cuartiles y Outliers (Edad) ---")
print(f"N√∫mero de observaciones (sin valores nulos): {len(df_age)}")

Q1 = df_age.quantile(0.25)
Q2 = df_age.quantile(0.5)
Q3 = df_age.quantile(0.75)

IQR = Q3 - Q1

lower_bound_outlier = Q1 - 1.5 * IQR #outlier por debajo.
upper_bound_outlier = Q3 + 1.5 * IQR #outlier por encima.

print(f"\nQ1 (25%): {Q1:.2f}")
print(f"Q2 (50%): {Q2:.2f}")
print(f"Q3 (75%): {Q3:.2f}")
print(f"IQR: {IQR:.2f}")
print(f"L√≠mite inferior para outliers: {lower_bound_outlier:.2f}")
print(f"L√≠mite superior para outliers: {upper_bound_outlier:.2f}")

# Identificar outliers
outliers = df[df['Age'].notna() & ((df['Age'] < lower_bound_outlier) | (df['Age'] > upper_bound_outlier))]

print(f"\nN√∫mero de outliers encontrados: {len(outliers)}")
print("\nPrimeros outliers seg√∫n la regla del 1.5 * IQR:")
print(outliers[['PassengerId', 'Name', 'Age', 'Pclass']].head())

# --- Visualizar con un Box Plot para confirmar ---
plt.figure(figsize=(8, 6))
sns.boxplot(y=df_age)
plt.title('Box Plot de Edad en el Titanic - Detecci√≥n de Outliers')
plt.ylabel('Edad')
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.savefig('01_boxplot_edad_outliers.png', dpi=300, bbox_inches='tight')
plt.show()

# --- An√°lisis de Percentiles (usando Age) ---
print("\n--- An√°lisis de Percentiles (Edad) ---")
print(f"N√∫mero total de datos (sin valores nulos): {len(df_age)}")

# --- Usando Pandas ---
# El m√©todo .quantile() espera la fracci√≥n (0.0 a 1.0)
# Calcular el percentil 70 (0.70)
percentil_70_pandas = df_age.quantile(0.70)
print(f"\nPercentil 70 (Pandas): {percentil_70_pandas:.2f} a√±os")

# Calcular m√∫ltiples percentiles a la vez (ej. P10, P50 (mediana), P90)
multi_percentiles_pandas = df_age.quantile([0.10, 0.50, 0.90])
print("\nM√∫ltiples percentiles (Pandas):")
print(multi_percentiles_pandas)

# --- Usando NumPy ---
# El m√©todo np.percentile() espera el percentil como un n√∫mero entero (0 a 100)
percentil_70_numpy = np.percentile(df_age, 70)
print(f"\nPercentil 70 (NumPy): {percentil_70_numpy:.2f} a√±os")

# Calcular m√∫ltiples percentiles con NumPy
multi_percentiles_numpy = np.percentile(df_age, [10, 50, 90])
print("\nM√∫ltiples percentiles (NumPy):")
print(multi_percentiles_numpy)


# ============================================
# MEDIDAS DE POSICI√ìN
# ============================================

print("\n" + "="*60)
print("MEDIDAS DE POSICI√ìN")
print("="*60)

# --- Deciles ---
print("\n--- Deciles (Edad) ---")
print("Los deciles dividen los datos en 10 partes iguales")
deciles = df_age.quantile([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])
for i, valor in enumerate(deciles, start=1):
    print(f"D{i} (Decil {i}): {valor:.2f} a√±os")

# --- Quintiles ---
print("\n--- Quintiles (Edad) ---")
print("Los quintiles dividen los datos en 5 partes iguales")
quintiles = df_age.quantile([0.2, 0.4, 0.6, 0.8])
for i, valor in enumerate(quintiles, start=1):
    print(f"Q{i} (Quintil {i}): {valor:.2f} a√±os")

# --- Medidas de Posici√≥n para Tarifa (Fare) ---
print("\n--- Medidas de Posici√≥n para Tarifa (Fare) ---")
df_fare = df['Fare'].dropna()

print(f"\nCuartiles de Tarifa:")
Q1_fare = df_fare.quantile(0.25)
Q2_fare = df_fare.quantile(0.50)
Q3_fare = df_fare.quantile(0.75)
print(f"Q1 (25%): ${Q1_fare:.2f}")
print(f"Q2 (50%): ${Q2_fare:.2f}")
print(f"Q3 (75%): ${Q3_fare:.2f}")

print(f"\nDeciles de Tarifa:")
deciles_fare = df_fare.quantile([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])
for i, valor in enumerate(deciles_fare, start=1):
    print(f"D{i}: ${valor:.2f}")


# ============================================
# ELIMINACI√ìN DE OUTLIERS
# ============================================

print("\n" + "="*60)
print("ELIMINACI√ìN DE OUTLIERS")
print("="*60)

# Crear una copia del dataframe original
df_sin_outliers = df.copy()

print(f"\n--- Dataset Original ---")
print(f"Total de registros: {len(df)}")
print(f"Total de valores de Edad (no nulos): {df['Age'].notna().sum()}")

# --- Eliminar outliers de Age ---
print("\n--- Eliminando Outliers de Edad ---")
print(f"L√≠mites para Age: [{lower_bound_outlier:.2f}, {upper_bound_outlier:.2f}]")

# Filtrar el dataframe: mantener solo las filas donde Age est√° dentro de los l√≠mites
# o donde Age es nulo (para no perder esos registros)
df_sin_outliers = df_sin_outliers[
    (df_sin_outliers['Age'].isna()) | 
    ((df_sin_outliers['Age'] >= lower_bound_outlier) & (df_sin_outliers['Age'] <= upper_bound_outlier))
]

print(f"Registros eliminados por outliers en Age: {len(df) - len(df_sin_outliers)}")
print(f"Total de registros despu√©s de eliminar outliers: {len(df_sin_outliers)}")

# --- Eliminar outliers de Fare ---
print("\n--- Eliminando Outliers de Tarifa (Fare) ---")
Q1_fare = df_sin_outliers['Fare'].quantile(0.25)
Q3_fare = df_sin_outliers['Fare'].quantile(0.75)
IQR_fare = Q3_fare - Q1_fare

lower_bound_fare = Q1_fare - 1.5 * IQR_fare
upper_bound_fare = Q3_fare + 1.5 * IQR_fare

print(f"L√≠mites para Fare: [{lower_bound_fare:.2f}, {upper_bound_fare:.2f}]")

outliers_fare = df_sin_outliers[
    (df_sin_outliers['Fare'].notna()) & 
    ((df_sin_outliers['Fare'] < lower_bound_fare) | (df_sin_outliers['Fare'] > upper_bound_fare))
]
print(f"Outliers detectados en Fare: {len(outliers_fare)}")

df_sin_outliers = df_sin_outliers[
    (df_sin_outliers['Fare'].isna()) | 
    ((df_sin_outliers['Fare'] >= lower_bound_fare) & (df_sin_outliers['Fare'] <= upper_bound_fare))
]

print(f"Registros eliminados por outliers en Fare: {len(df) - len(df_sin_outliers) - len(outliers)}")
print(f"Total de registros despu√©s de eliminar todos los outliers: {len(df_sin_outliers)}")

# --- Comparaci√≥n antes y despu√©s ---
print("\n--- Comparaci√≥n de Estad√≠sticas: Original vs Sin Outliers ---")

print("\nEdad (Age):")
print(f"  Original - Media: {df['Age'].mean():.2f}, Mediana: {df['Age'].median():.2f}, Std: {df['Age'].std():.2f}")
print(f"  Sin Outliers - Media: {df_sin_outliers['Age'].mean():.2f}, Mediana: {df_sin_outliers['Age'].median():.2f}, Std: {df_sin_outliers['Age'].std():.2f}")

print("\nTarifa (Fare):")
print(f"  Original - Media: {df['Fare'].mean():.2f}, Mediana: {df['Fare'].median():.2f}, Std: {df['Fare'].std():.2f}")
print(f"  Sin Outliers - Media: {df_sin_outliers['Fare'].mean():.2f}, Mediana: {df_sin_outliers['Fare'].median():.2f}, Std: {df_sin_outliers['Fare'].std():.2f}")

# --- Visualizaci√≥n comparativa ---
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# Box plot Age - Original
axes[0, 0].boxplot(df['Age'].dropna())
axes[0, 0].set_title('Age - Original')
axes[0, 0].set_ylabel('Edad')
axes[0, 0].grid(axis='y', alpha=0.3)

# Box plot Age - Sin Outliers
axes[0, 1].boxplot(df_sin_outliers['Age'].dropna())
axes[0, 1].set_title('Age - Sin Outliers')
axes[0, 1].set_ylabel('Edad')
axes[0, 1].grid(axis='y', alpha=0.3)

# Box plot Fare - Original
axes[1, 0].boxplot(df['Fare'].dropna())
axes[1, 0].set_title('Fare - Original')
axes[1, 0].set_ylabel('Tarifa ($)')
axes[1, 0].grid(axis='y', alpha=0.3)

# Box plot Fare - Sin Outliers
axes[1, 1].boxplot(df_sin_outliers['Fare'].dropna())
axes[1, 1].set_title('Fare - Sin Outliers')
axes[1, 1].set_ylabel('Tarifa ($)')
axes[1, 1].grid(axis='y', alpha=0.3)

plt.tight_layout()
plt.suptitle('Comparaci√≥n: Dataset Original vs Sin Outliers', y=1.02, fontsize=14, fontweight='bold')
plt.savefig('02_comparacion_outliers_eliminados.png', dpi=300, bbox_inches='tight')
plt.show()

print("\n--- Dataset limpio guardado en variable 'df_sin_outliers' ---")
print(f"Forma final: {df_sin_outliers.shape}")


# ============================================
# AN√ÅLISIS DE DISTRIBUCI√ìN DE SALARIOS
# ============================================
# Nota: %reset -f es un comando de IPython/Jupyter, no aplicable en scripts .py

print("\n" + "="*60)
print("AN√ÅLISIS DE DISTRIBUCI√ìN DE SALARIOS")
print("="*60)

# Generar un DataFrame de salarios anuales (reutilizando el ejemplo anterior)
np.random.seed(42) # Para reproducibilidad

salarios_bajos = np.random.normal(loc=40000, scale=8000, size=900)
salarios_altos = np.random.normal(loc=120000, scale=25000, size=100)
salarios_super_altos = np.random.normal(loc=300000, scale=50000, size=10)

salarios = np.concatenate([salarios_bajos, salarios_altos, salarios_super_altos])

#Evitar valores negativos o irrealmente bajos:
salarios = np.maximum(salarios, 15000)

df_salarios = pd.DataFrame({'Salario_Anual': salarios})

print("\nDataFrame de Salarios (primeras 5 filas):")
print(df_salarios.head())
print(f"\nN√∫mero total de empleados: {len(df_salarios)}")

# Calcular la media y la mediana para visualizarlas en el histograma
media_salario = df_salarios['Salario_Anual'].mean()
mediana_salario = df_salarios['Salario_Anual'].median()

# --- Crear el Histograma ---
plt.figure(figsize=(12, 6)) # Define el tama√±o de la figura

# data: el DataFrame
# x: la columna que queremos graficar
# bins: N√∫mero de intervalos o una secuencia de bordes de bin
# color: Color de las barras
#sns.histplot(data=df_salarios, x='Salario_Anual', kde=True, bins=50, color='skyblue')
sns.histplot(data=df_salarios, x='Salario_Anual', bins=50, color='skyblue')

# A√±adir l√≠neas para la media y la mediana (opcional, pero √∫til para EDA)
plt.axvline(media_salario, color='red', linestyle='--', label=f'Media: ${media_salario:,.0f}')
plt.axvline(mediana_salario, color='green', linestyle='-', label=f'Mediana: ${mediana_salario:,.0f}')

# A√±adir t√≠tulo y etiquetas a los ejes
plt.title('Distribuci√≥n de Salarios Anuales (Histograma)', fontsize=16)
plt.xlabel('Salario Anual ($)', fontsize=12)
plt.ylabel('Frecuencia de Empleados', fontsize=12)

# A√±adir leyenda y cuadr√≠cula
plt.legend()
plt.grid(axis='y', linestyle='--', alpha=0.7)

# Mostrar el gr√°fico
plt.savefig('03_histograma_salarios.png', dpi=300, bbox_inches='tight')
plt.show()


# ============================================
# GR√ÅFICOS DE DISPERSI√ìN
# ============================================
# Nota: %reset -f es un comando de IPython/Jupyter, no aplicable en scripts .py

print("\n" + "="*60)
print("GR√ÅFICOS DE DISPERSI√ìN - AN√ÅLISIS DE RELACIONES")
print("="*60)

# Usaremos el DataFrame del Titanic (df) para analizar relaciones entre variables
# Vamos a crear varios gr√°ficos de dispersi√≥n para diferentes pares de variables

# --- Gr√°fico 1: Age vs Fare ---
print("\n--- An√°lisis 1: Relaci√≥n entre Edad y Tarifa ---")

# Crear un DataFrame sin valores nulos para estas columnas
df_age_fare = df[['Age', 'Fare']].dropna()
print(f"N√∫mero de registros v√°lidos (Age y Fare sin nulos): {len(df_age_fare)}")

# Calcular la correlaci√≥n
correlacion_age_fare = df_age_fare['Age'].corr(df_age_fare['Fare'])
print(f"Coeficiente de Correlaci√≥n entre Age y Fare: {correlacion_age_fare:.3f}")

# Crear el gr√°fico de dispersi√≥n
plt.figure(figsize=(10, 7))
sns.scatterplot(x='Age', y='Fare', data=df_age_fare, color='teal', alpha=0.6, s=80)

# A√±adir l√≠nea de regresi√≥n para visualizar la tendencia
sns.regplot(x='Age', y='Fare', data=df_age_fare, 
            scatter=False, color='red', line_kws={'linestyle':'--', 'linewidth':2}, 
            label=f'L√≠nea de Tendencia (r={correlacion_age_fare:.3f})')

plt.title('Relaci√≥n entre Edad y Tarifa Pagada - Titanic', fontsize=16)
plt.xlabel('Edad (a√±os)', fontsize=12)
plt.ylabel('Tarifa Pagada ($)', fontsize=12)
plt.grid(True, linestyle='--', alpha=0.6)
plt.legend()
plt.tight_layout()
plt.savefig('04_dispersion_age_vs_fare.png', dpi=300, bbox_inches='tight')
plt.show()


# --- Gr√°fico 2: Age vs Pclass (con color por clase) ---
print("\n--- An√°lisis 2: Relaci√≥n entre Edad y Clase de Pasajero ---")

df_age_pclass = df[['Age', 'Pclass', 'Survived']].dropna()
print(f"N√∫mero de registros v√°lidos: {len(df_age_pclass)}")

# Crear el gr√°fico de dispersi√≥n con colores por Pclass
plt.figure(figsize=(10, 7))
sns.scatterplot(x='Pclass', y='Age', data=df_age_pclass, 
                hue='Survived', palette={0: 'red', 1: 'green'}, 
                alpha=0.6, s=80)

plt.title('Relaci√≥n entre Clase de Pasajero y Edad (por Supervivencia)', fontsize=16)
plt.xlabel('Clase de Pasajero (1=Primera, 2=Segunda, 3=Tercera)', fontsize=12)
plt.ylabel('Edad (a√±os)', fontsize=12)
plt.grid(True, linestyle='--', alpha=0.6)
plt.legend(title='Sobrevivi√≥', labels=['No', 'S√≠'])
plt.tight_layout()
plt.savefig('05_dispersion_age_vs_pclass.png', dpi=300, bbox_inches='tight')
plt.show()


# --- Gr√°fico 3: SibSp vs Parch ---
print("\n--- An√°lisis 3: Relaci√≥n entre Hermanos/C√≥nyuges y Padres/Hijos ---")

df_family = df[['SibSp', 'Parch', 'Survived']].dropna()
print(f"N√∫mero de registros v√°lidos: {len(df_family)}")

# Calcular la correlaci√≥n
correlacion_family = df_family['SibSp'].corr(df_family['Parch'])
print(f"Coeficiente de Correlaci√≥n entre SibSp y Parch: {correlacion_family:.3f}")

# Crear el gr√°fico de dispersi√≥n
plt.figure(figsize=(10, 7))
sns.scatterplot(x='SibSp', y='Parch', data=df_family,
                hue='Survived', palette={0: 'red', 1: 'green'},
                alpha=0.6, s=100)

plt.title('Relaci√≥n entre Hermanos/C√≥nyuges y Padres/Hijos a Bordo', fontsize=16)
plt.xlabel('N√∫mero de Hermanos/C√≥nyuges a Bordo', fontsize=12)
plt.ylabel('N√∫mero de Padres/Hijos a Bordo', fontsize=12)
plt.grid(True, linestyle='--', alpha=0.6)
plt.legend(title='Sobrevivi√≥', labels=['No', 'S√≠'])
plt.tight_layout()
plt.savefig('06_dispersion_sibsp_vs_parch.png', dpi=300, bbox_inches='tight')
plt.show()


# --- Gr√°fico 4: Fare vs Pclass ---
print("\n--- An√°lisis 4: Relaci√≥n entre Tarifa y Clase de Pasajero ---")

df_fare_pclass = df[['Fare', 'Pclass']].dropna()
print(f"N√∫mero de registros v√°lidos: {len(df_fare_pclass)}")

# Calcular la correlaci√≥n
correlacion_fare_pclass = df_fare_pclass['Pclass'].corr(df_fare_pclass['Fare'])
print(f"Coeficiente de Correlaci√≥n entre Pclass y Fare: {correlacion_fare_pclass:.3f}")

# Crear el gr√°fico de dispersi√≥n con jitter para ver mejor los puntos
plt.figure(figsize=(10, 7))
sns.stripplot(x='Pclass', y='Fare', data=df_fare_pclass, 
              alpha=0.5, jitter=True, size=4, color='steelblue')

# A√±adir box plot superpuesto para ver la distribuci√≥n
sns.boxplot(x='Pclass', y='Fare', data=df_fare_pclass, 
            width=0.3, showfliers=False, color='lightcoral', 
            boxprops=dict(alpha=0.5), whiskerprops=dict(alpha=0.5),
            capprops=dict(alpha=0.5), medianprops=dict(color='red', linewidth=2))

plt.title('Relaci√≥n entre Clase de Pasajero y Tarifa Pagada', fontsize=16)
plt.xlabel('Clase de Pasajero (1=Primera, 2=Segunda, 3=Tercera)', fontsize=12)
plt.ylabel('Tarifa Pagada ($)', fontsize=12)
plt.grid(True, linestyle='--', alpha=0.6, axis='y')
plt.tight_layout()
plt.savefig('07_dispersion_fare_vs_pclass.png', dpi=300, bbox_inches='tight')
plt.show()


# --- Matriz de Correlaci√≥n para Variables Num√©ricas ---
print("\n--- Matriz de Correlaci√≥n entre Variables Num√©ricas ---")

# Seleccionar solo columnas num√©ricas
columnas_numericas = ['Age', 'Fare', 'SibSp', 'Parch', 'Pclass', 'Survived']
df_correlacion = df[columnas_numericas].dropna()

# Calcular la matriz de correlaci√≥n
matriz_correlacion = df_correlacion.corr()
print("\nMatriz de Correlaci√≥n:")
print(matriz_correlacion)

# Visualizar con un heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(matriz_correlacion, annot=True, cmap='coolwarm', center=0,
            fmt='.3f', linewidths=0.5, square=True, cbar_kws={'label': 'Correlaci√≥n'})
plt.title('Matriz de Correlaci√≥n - Variables del Titanic', fontsize=16)
plt.tight_layout()
plt.savefig('08_matriz_correlacion.png', dpi=300, bbox_inches='tight')
plt.show()

print("\n--- An√°lisis de Gr√°ficos de Dispersi√≥n Completado ---")


# ============================================
# TRANSFORMACI√ìN DE COLUMNAS - ENCODING
# ============================================

print("\n" + "="*60)
print("TRANSFORMACI√ìN DE COLUMNAS - ENCODING")
print("="*60)

# Trabajaremos con una copia del DataFrame original del Titanic
df_encoding = df.copy()

# --- ONE HOT ENCODING ---
print("\n--- 1. ONE HOT ENCODING ---")
print("Transforma variables categ√≥ricas en columnas binarias (0 o 1)")
print("\nColumnas categ√≥ricas originales: Sex, Embarked")

# Mostrar distribuci√≥n original
print("\nDistribuci√≥n de 'Sex':")
print(df_encoding['Sex'].value_counts())
print("\nDistribuci√≥n de 'Embarked':")
print(df_encoding['Embarked'].value_counts())

# Aplicar One-Hot Encoding a las columnas Sex y Embarked
df_one_hot = pd.get_dummies(df_encoding, columns=['Sex', 'Embarked'], prefix=['Sex', 'Embarked'])

print("\nDataFrame despu√©s de One-Hot Encoding (primeras 5 filas):")
print(df_one_hot[['PassengerId', 'Name', 'Sex_female', 'Sex_male', 
                   'Embarked_C', 'Embarked_Q', 'Embarked_S']].head())

print(f"\nColumnas agregadas: {[col for col in df_one_hot.columns if col.startswith(('Sex_', 'Embarked_'))]}")
print(f"Forma del DataFrame Original: {df_encoding.shape}")
print(f"Forma del DataFrame con One-Hot: {df_one_hot.shape}")


# --- LABEL ENCODING ---
print("\n" + "="*60)
print("--- 2. LABEL ENCODING ---")
print("Asigna un n√∫mero entero √∫nico a cada categor√≠a")

from sklearn.preprocessing import LabelEncoder

# Crear una copia para Label Encoding
df_label = df_encoding.copy()

# Aplicar Label Encoding a la columna 'Sex'
le_sex = LabelEncoder()
df_label['Sex_Encoded'] = le_sex.fit_transform(df_label['Sex'])

print("\nLabel Encoding para 'Sex':")
print(f"Categor√≠as originales: {le_sex.classes_}")
print(f"Mapeo: {dict(zip(le_sex.classes_, le_sex.transform(le_sex.classes_)))}")
print("\nComparaci√≥n:")
print(df_label[['PassengerId', 'Name', 'Sex', 'Sex_Encoded']].head(10))

# Aplicar Label Encoding a la columna 'Embarked' (eliminando nulos primero)
df_label_embarked = df_label[df_label['Embarked'].notna()].copy()
le_embarked = LabelEncoder()
df_label_embarked['Embarked_Encoded'] = le_embarked.fit_transform(df_label_embarked['Embarked'])

print("\nLabel Encoding para 'Embarked':")
print(f"Categor√≠as originales: {le_embarked.classes_}")
print(f"Mapeo: {dict(zip(le_embarked.classes_, le_embarked.transform(le_embarked.classes_)))}")
print("\nComparaci√≥n:")
print(df_label_embarked[['PassengerId', 'Name', 'Embarked', 'Embarked_Encoded']].head(10))


# --- BINARY ENCODING ---
print("\n" + "="*60)
print("--- 3. BINARY ENCODING ---")
print("Convierte categor√≠as a representaci√≥n binaria (m√°s eficiente para muchas categor√≠as)")

# Verificar si category_encoders est√° instalado, si no, intentar instalarlo
try:
    import category_encoders as ce
except ImportError:
    print("\nInstalando category_encoders...")
    import subprocess
    subprocess.check_call([sys.executable, "-m", "pip", "install", "category_encoders", "-q"])
    import category_encoders as ce

# Crear una copia para Binary Encoding
df_binary = df_encoding.copy()

# Aplicar Binary Encoding a la columna 'Embarked'
# Primero llenamos los nulos con 'Unknown'
df_binary['Embarked'] = df_binary['Embarked'].fillna('Unknown')

encoder_embarked = ce.BinaryEncoder(cols=['Embarked'])
df_binary_embarked = encoder_embarked.fit_transform(df_binary['Embarked'])

print("\nBinary Encoding para 'Embarked':")
print(f"Categor√≠as originales: C, Q, S, Unknown")
print("\nColumnas generadas por Binary Encoding:")
print(df_binary_embarked.head(10))

# Concatenar con el dataframe original
df_binary = pd.concat([df_binary, df_binary_embarked], axis=1)

print("\nDataFrame con Binary Encoding (muestra):")
print(df_binary[['PassengerId', 'Name', 'Embarked'] + list(df_binary_embarked.columns)].head(10))


# Aplicar Binary Encoding a la columna 'Pclass' (aunque es num√©rica, la trataremos como categ√≥rica)
encoder_pclass = ce.BinaryEncoder(cols=['Pclass'])
df_binary_pclass = encoder_pclass.fit_transform(df_binary[['Pclass']])

print("\nBinary Encoding para 'Pclass':")
print(f"Categor√≠as originales: 1, 2, 3")
print("\nColumnas generadas:")
print(df_binary_pclass.head(10))


# --- COMPARACI√ìN DE T√âCNICAS ---
print("\n" + "="*60)
print("COMPARACI√ìN DE T√âCNICAS DE ENCODING")
print("="*60)

print("\n1. ONE-HOT ENCODING:")
print("   ‚úì Ventajas: F√°cil de interpretar, no asume orden entre categor√≠as")
print("   ‚úó Desventajas: Aumenta mucho las dimensiones con muchas categor√≠as")
print(f"   Ejemplo: 'Embarked' (3 categor√≠as) ‚Üí 3 columnas binarias")

print("\n2. LABEL ENCODING:")
print("   ‚úì Ventajas: Muy simple, no aumenta dimensiones")
print("   ‚úó Desventajas: Asume orden entre categor√≠as (puede confundir al modelo)")
print(f"   Ejemplo: 'Embarked' (3 categor√≠as) ‚Üí 1 columna con valores 0, 1, 2")

print("\n3. BINARY ENCODING:")
print("   ‚úì Ventajas: M√°s eficiente que One-Hot, mantiene baja dimensionalidad")
print("   ‚úó Desventajas: Menos interpretable, requiere librer√≠a adicional")
print(f"   Ejemplo: 'Embarked' (4 categor√≠as con Unknown) ‚Üí 2 columnas binarias")

print("\n" + "="*60)
print("RESUMEN DE SHAPES")
print("="*60)
print(f"DataFrame Original: {df_encoding.shape}")
print(f"Con One-Hot Encoding: {df_one_hot.shape}")
print(f"Con Label Encoding: {df_label.shape} (mismo tama√±o, solo nuevas columnas)")
print(f"Con Binary Encoding: {df_binary.shape}")

print("\n--- Transformaci√≥n de Columnas Completada ---")


# ============================================
# AN√ÅLISIS DE CORRELACI√ìN Y SELECCI√ìN DE COLUMNAS
# ============================================

print("\n" + "="*60)
print("AN√ÅLISIS DE CORRELACI√ìN ENTRE COLUMNAS")
print("="*60)

# Seleccionar solo las columnas num√©ricas del DataFrame original
columnas_numericas = ['Age', 'Fare', 'SibSp', 'Parch', 'Pclass', 'Survived']
df_correlacion = df[columnas_numericas].copy()

# Eliminar filas con valores nulos para el an√°lisis
print(f"\nFilas originales: {len(df)}")
df_correlacion = df_correlacion.dropna()
print(f"Filas despu√©s de eliminar nulos: {len(df_correlacion)}")

# --- Correlaci√≥n entre dos columnas espec√≠ficas ---
print("\n--- Correlaci√≥n entre columnas espec√≠ficas ---")

# Correlaci√≥n Age vs Fare
corr_age_fare = df_correlacion['Age'].corr(df_correlacion['Fare'])
print(f"Correlaci√≥n entre Age y Fare: {corr_age_fare:.4f}")

# Correlaci√≥n SibSp vs Parch
corr_sibsp_parch = df_correlacion['SibSp'].corr(df_correlacion['Parch'])
print(f"Correlaci√≥n entre SibSp y Parch: {corr_sibsp_parch:.4f}")

# Correlaci√≥n Pclass vs Fare
corr_pclass_fare = df_correlacion['Pclass'].corr(df_correlacion['Fare'])
print(f"Correlaci√≥n entre Pclass y Fare: {corr_pclass_fare:.4f}")

# Correlaci√≥n Pclass vs Survived
corr_pclass_survived = df_correlacion['Pclass'].corr(df_correlacion['Survived'])
print(f"Correlaci√≥n entre Pclass y Survived: {corr_pclass_survived:.4f}")


# --- Matriz de Correlaci√≥n Completa ---
print("\n--- Matriz de Correlaci√≥n Completa ---")
matriz_corr = df_correlacion.corr()
print("\nMatriz de correlaci√≥n:")
print(matriz_corr.round(3))


# --- Visualizaci√≥n: Mapa de Calor de Correlaciones ---
plt.figure(figsize=(10, 8))
sns.heatmap(matriz_corr, annot=True, cmap='coolwarm', center=0,
            fmt='.3f', linewidths=1, square=True, 
            cbar_kws={'label': 'Coeficiente de Correlaci√≥n'},
            vmin=-1, vmax=1)
plt.title('Mapa de Calor de Correlaciones - Dataset Titanic', fontsize=16, pad=20)
plt.tight_layout()
plt.savefig('09_heatmap_correlaciones.png', dpi=300, bbox_inches='tight')
plt.show()


# --- An√°lisis de Correlaci√≥n con Pearson y Spearman ---
print("\n" + "="*60)
print("COMPARACI√ìN: CORRELACI√ìN PEARSON VS SPEARMAN")
print("="*60)

print("\nPearson: Mide relaciones LINEALES")
print("Spearman: Mide relaciones MONOT√ìNICAS (lineales o no)")

# Comparar ambos m√©todos para algunas variables clave
print("\n--- Age vs Fare ---")
pearson_af = df_correlacion['Age'].corr(df_correlacion['Fare'], method='pearson')
spearman_af = df_correlacion['Age'].corr(df_correlacion['Fare'], method='spearman')
print(f"Pearson:  {pearson_af:.4f}")
print(f"Spearman: {spearman_af:.4f}")

print("\n--- Pclass vs Fare ---")
pearson_pf = df_correlacion['Pclass'].corr(df_correlacion['Fare'], method='pearson')
spearman_pf = df_correlacion['Pclass'].corr(df_correlacion['Fare'], method='spearman')
print(f"Pearson:  {pearson_pf:.4f}")
print(f"Spearman: {spearman_pf:.4f}")

print("\n--- SibSp vs Parch ---")
pearson_sp = df_correlacion['SibSp'].corr(df_correlacion['Parch'], method='pearson')
spearman_sp = df_correlacion['SibSp'].corr(df_correlacion['Parch'], method='spearman')
print(f"Pearson:  {pearson_sp:.4f}")
print(f"Spearman: {spearman_sp:.4f}")


# --- Identificar columnas altamente correlacionadas ---
print("\n" + "="*60)
print("IDENTIFICACI√ìN DE COLUMNAS ALTAMENTE CORRELACIONADAS")
print("="*60)

# Definir umbral para correlaci√≥n alta (t√≠picamente > 0.7 o < -0.7)
umbral_correlacion = 0.7

print(f"\nUmbral de correlaci√≥n alta: ¬±{umbral_correlacion}")
print("\nPares de variables con correlaci√≥n alta:")

# Buscar correlaciones altas (excluyendo la diagonal)
encontrado = False
for i in range(len(matriz_corr.columns)):
    for j in range(i+1, len(matriz_corr.columns)):
        corr_value = matriz_corr.iloc[i, j]
        if abs(corr_value) >= umbral_correlacion:
            var1 = matriz_corr.columns[i]
            var2 = matriz_corr.columns[j]
            print(f"  ‚Ä¢ {var1} vs {var2}: {corr_value:.4f}")
            encontrado = True

if not encontrado:
    print(f"  No se encontraron pares de variables con correlaci√≥n >= {umbral_correlacion}")


# --- Recomendaciones para eliminaci√≥n de columnas ---
print("\n" + "="*60)
print("RECOMENDACIONES PARA ELIMINACI√ìN DE COLUMNAS")
print("="*60)

print("\nüìä CRITERIOS DE DECISI√ìN:")
print("  ‚Ä¢ Correlaci√≥n alta (|r| > 0.7): Considerar eliminar una de las dos")
print("  ‚Ä¢ Correlaci√≥n moderada (0.5 < |r| < 0.7): Evaluar seg√∫n contexto")
print("  ‚Ä¢ Correlaci√≥n baja (|r| < 0.5): Mantener ambas columnas")

print("\nüîç AN√ÅLISIS DEL DATASET TITANIC:")

# Evaluar cada par de correlaciones
correlaciones_importantes = []
for i in range(len(matriz_corr.columns)):
    for j in range(i+1, len(matriz_corr.columns)):
        corr_value = abs(matriz_corr.iloc[i, j])
        if corr_value >= 0.5:  # Correlaci√≥n moderada o alta
            var1 = matriz_corr.columns[i]
            var2 = matriz_corr.columns[j]
            correlaciones_importantes.append((var1, var2, matriz_corr.iloc[i, j]))

if correlaciones_importantes:
    print("\nPares con correlaci√≥n moderada o alta:")
    for var1, var2, corr_val in sorted(correlaciones_importantes, key=lambda x: abs(x[2]), reverse=True):
        if abs(corr_val) >= 0.7:
            nivel = "‚ö†Ô∏è ALTA"
        else:
            nivel = "‚ö° MODERADA"
        print(f"  {nivel} - {var1} vs {var2}: {corr_val:.4f}")
else:
    print("\nNo hay pares con correlaci√≥n moderada o alta.")

print("\nüí° RECOMENDACIONES ESPEC√çFICAS:")

# Analizar correlaciones espec√≠ficas del Titanic
if abs(matriz_corr.loc['Pclass', 'Fare']) >= 0.5:
    print(f"\n  1. Pclass vs Fare (r={matriz_corr.loc['Pclass', 'Fare']:.3f}):")
    print("     ‚Üí Correlaci√≥n moderada/alta NEGATIVA")
    print("     ‚Üí A mayor clase (3), menor tarifa")
    print("     ‚Üí RECOMENDACI√ìN: MANTENER ambas")
    print("       ‚Ä¢ Pclass: Variable categ√≥rica ordinal importante")
    print("       ‚Ä¢ Fare: Variable continua con informaci√≥n √∫nica")

if abs(matriz_corr.loc['SibSp', 'Parch']) >= 0.3:
    print(f"\n  2. SibSp vs Parch (r={matriz_corr.loc['SibSp', 'Parch']:.3f}):")
    print("     ‚Üí Correlaci√≥n baja/moderada POSITIVA")
    print("     ‚Üí Ambas relacionadas con tama√±o de familia")
    print("     ‚Üí RECOMENDACI√ìN: MANTENER ambas")
    print("       ‚Ä¢ Representan relaciones familiares diferentes")
    print("       ‚Ä¢ O crear una nueva variable 'FamilySize' = SibSp + Parch + 1")

if abs(matriz_corr.loc['Age', 'Fare']) < 0.2:
    print(f"\n  3. Age vs Fare (r={matriz_corr.loc['Age', 'Fare']:.3f}):")
    print("     ‚Üí Correlaci√≥n MUY BAJA")
    print("     ‚Üí Variables independientes entre s√≠")
    print("     ‚Üí RECOMENDACI√ìN: MANTENER ambas")

print("\n‚úÖ CONCLUSI√ìN FINAL:")
print("  En el dataset del Titanic, NO hay columnas con correlaci√≥n")
print("  lo suficientemente alta como para recomendar su eliminaci√≥n.")
print("  Todas las variables aportan informaci√≥n √∫nica y valiosa.")

# --- Crear DataFrame con variables seleccionadas (ejemplo) ---
print("\n" + "="*60)
print("CREACI√ìN DE DATASET CON FEATURE ENGINEERING")
print("="*60)

# Crear una nueva variable combinando SibSp y Parch
df_final = df_correlacion.copy()
df_final['FamilySize'] = df_final['SibSp'] + df_final['Parch'] + 1
df_final['IsAlone'] = (df_final['FamilySize'] == 1).astype(int)

print("\nNuevas variables creadas:")
print("  ‚Ä¢ FamilySize: SibSp + Parch + 1")
print("  ‚Ä¢ IsAlone: 1 si viajaba solo, 0 si con familia")

print("\nDataFrame final (primeras 10 filas):")
print(df_final[['Age', 'Fare', 'SibSp', 'Parch', 'FamilySize', 'IsAlone', 'Survived']].head(10))

# Correlaci√≥n de las nuevas variables con Survived
print("\nCorrelaci√≥n de nuevas variables con Survived:")
print(f"  FamilySize vs Survived: {df_final['FamilySize'].corr(df_final['Survived']):.4f}")
print(f"  IsAlone vs Survived:   {df_final['IsAlone'].corr(df_final['Survived']):.4f}")

print("\n--- An√°lisis de Correlaci√≥n Completado ---")

# ============================================
# TRANSFORMACI√ìN LOGAR√çTMICA
# ============================================

print("\n" + "="*60)
print("TRANSFORMACI√ìN LOGAR√çTMICA")
print("="*60)

print("\nüìå ¬øCU√ÅNDO APLICAR TRANSFORMACI√ìN LOGAR√çTMICA?")
print("  ‚Ä¢ Datos con distribuci√≥n muy sesgada (asim√©trica)")
print("  ‚Ä¢ Valores muy dispersos (outliers extremos)")
print("  ‚Ä¢ Diferencias de escala de varios √≥rdenes de magnitud")
print("  ‚Ä¢ Para estabilizar varianza y hacer datos m√°s 'normales'")

# --- An√°lisis de la distribuci√≥n de Fare ---
print("\n" + "="*60)
print("AN√ÅLISIS: ¬øFARE NECESITA TRANSFORMACI√ìN LOGAR√çTMICA?")
print("="*60)

df_fare_analysis = df[df['Fare'] > 0].copy()  # Eliminar Fare = 0 para poder aplicar log
print(f"\nRegistros con Fare > 0: {len(df_fare_analysis)}")
print(f"Registros con Fare = 0: {len(df[df['Fare'] == 0])}")

# Estad√≠sticas de Fare original
print("\nüìä Estad√≠sticas de 'Fare' (Original):")
print(f"  M√≠nimo:  ${df_fare_analysis['Fare'].min():.2f}")
print(f"  Q1:      ${df_fare_analysis['Fare'].quantile(0.25):.2f}")
print(f"  Mediana: ${df_fare_analysis['Fare'].median():.2f}")
print(f"  Q3:      ${df_fare_analysis['Fare'].quantile(0.75):.2f}")
print(f"  M√°ximo:  ${df_fare_analysis['Fare'].max():.2f}")
print(f"  Media:   ${df_fare_analysis['Fare'].mean():.2f}")
print(f"  Desv. Std: ${df_fare_analysis['Fare'].std():.2f}")

# Calcular asimetr√≠a (skewness)
skewness_fare = df_fare_analysis['Fare'].skew()
print(f"\n  Asimetr√≠a (Skewness): {skewness_fare:.3f}")
print("    ‚Üí Skewness > 1: Altamente sesgada a la derecha ‚úì")
print("    ‚Üí ¬°NECESITA TRANSFORMACI√ìN LOGAR√çTMICA!")

# --- Aplicar Transformaci√≥n Logar√≠tmica ---
print("\n--- Aplicando Transformaci√≥n Logar√≠tmica (Log10) ---")

# Aplicar log10 a Fare (solo valores > 0)
df_fare_analysis['Fare_Log10'] = np.log10(df_fare_analysis['Fare'])

# Estad√≠sticas despu√©s de la transformaci√≥n
print("\nüìä Estad√≠sticas de 'Fare_Log10' (Transformado):")
print(f"  M√≠nimo:  {df_fare_analysis['Fare_Log10'].min():.3f}")
print(f"  Q1:      {df_fare_analysis['Fare_Log10'].quantile(0.25):.3f}")
print(f"  Mediana: {df_fare_analysis['Fare_Log10'].median():.3f}")
print(f"  Q3:      {df_fare_analysis['Fare_Log10'].quantile(0.75):.3f}")
print(f"  M√°ximo:  {df_fare_analysis['Fare_Log10'].max():.3f}")
print(f"  Media:   {df_fare_analysis['Fare_Log10'].mean():.3f}")
print(f"  Desv. Std: {df_fare_analysis['Fare_Log10'].std():.3f}")

skewness_fare_log = df_fare_analysis['Fare_Log10'].skew()
print(f"\n  Asimetr√≠a (Skewness): {skewness_fare_log:.3f}")
print("    ‚Üí Skewness reducida significativamente ‚úì")
print("    ‚Üí Distribuci√≥n m√°s sim√©trica y 'normal'")

# --- Visualizaci√≥n: Antes y Despu√©s ---
print("\n--- Generando Visualizaci√≥n Comparativa ---")

fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# 1. Histograma Fare Original
sns.histplot(df_fare_analysis['Fare'], bins=50, kde=True, ax=axes[0, 0], color='skyblue')
axes[0, 0].set_title('Distribuci√≥n Original de Fare', fontsize=14, fontweight='bold')
axes[0, 0].set_xlabel('Tarifa ($)', fontsize=11)
axes[0, 0].set_ylabel('Frecuencia', fontsize=11)
axes[0, 0].axvline(df_fare_analysis['Fare'].mean(), color='red', linestyle='--', 
                   label=f'Media: ${df_fare_analysis["Fare"].mean():.2f}')
axes[0, 0].axvline(df_fare_analysis['Fare'].median(), color='green', linestyle='-', 
                   label=f'Mediana: ${df_fare_analysis["Fare"].median():.2f}')
axes[0, 0].legend()
axes[0, 0].grid(axis='y', alpha=0.3)

# 2. Histograma Fare Logar√≠tmico
sns.histplot(df_fare_analysis['Fare_Log10'], bins=30, kde=True, ax=axes[0, 1], color='salmon')
axes[0, 1].set_title('Distribuci√≥n Transformada (Log10)', fontsize=14, fontweight='bold')
axes[0, 1].set_xlabel('Log10(Tarifa)', fontsize=11)
axes[0, 1].set_ylabel('Frecuencia', fontsize=11)
axes[0, 1].axvline(df_fare_analysis['Fare_Log10'].mean(), color='red', linestyle='--', 
                   label=f'Media: {df_fare_analysis["Fare_Log10"].mean():.3f}')
axes[0, 1].axvline(df_fare_analysis['Fare_Log10'].median(), color='green', linestyle='-', 
                   label=f'Mediana: {df_fare_analysis["Fare_Log10"].median():.3f}')
axes[0, 1].legend()
axes[0, 1].grid(axis='y', alpha=0.3)

# 3. Box Plot Fare Original
axes[1, 0].boxplot(df_fare_analysis['Fare'], vert=True)
axes[1, 0].set_title('Box Plot - Fare Original', fontsize=14, fontweight='bold')
axes[1, 0].set_ylabel('Tarifa ($)', fontsize=11)
axes[1, 0].grid(axis='y', alpha=0.3)

# 4. Box Plot Fare Logar√≠tmico
axes[1, 1].boxplot(df_fare_analysis['Fare_Log10'], vert=True)
axes[1, 1].set_title('Box Plot - Fare Transformado (Log10)', fontsize=14, fontweight='bold')
axes[1, 1].set_ylabel('Log10(Tarifa)', fontsize=11)
axes[1, 1].grid(axis='y', alpha=0.3)

plt.tight_layout()
plt.suptitle('Comparaci√≥n: Transformaci√≥n Logar√≠tmica de Fare', 
             y=1.01, fontsize=16, fontweight='bold')
plt.savefig('10_transformacion_logaritmica_fare.png', dpi=300, bbox_inches='tight')
plt.show()


# --- An√°lisis de Age (opcional) ---
print("\n" + "="*60)
print("AN√ÅLISIS: ¬øAGE NECESITA TRANSFORMACI√ìN LOGAR√çTMICA?")
print("="*60)

df_age_analysis = df[df['Age'].notna()].copy()
print(f"\nRegistros con Age v√°lida: {len(df_age_analysis)}")

# Estad√≠sticas de Age
print("\nüìä Estad√≠sticas de 'Age' (Original):")
print(f"  M√≠nimo:  {df_age_analysis['Age'].min():.2f} a√±os")
print(f"  Q1:      {df_age_analysis['Age'].quantile(0.25):.2f} a√±os")
print(f"  Mediana: {df_age_analysis['Age'].median():.2f} a√±os")
print(f"  Q3:      {df_age_analysis['Age'].quantile(0.75):.2f} a√±os")
print(f"  M√°ximo:  {df_age_analysis['Age'].max():.2f} a√±os")
print(f"  Media:   {df_age_analysis['Age'].mean():.2f} a√±os")

skewness_age = df_age_analysis['Age'].skew()
print(f"\n  Asimetr√≠a (Skewness): {skewness_age:.3f}")
if abs(skewness_age) < 0.5:
    print("    ‚Üí Skewness < 0.5: Distribuci√≥n relativamente sim√©trica")
    print("    ‚Üí NO NECESITA transformaci√≥n logar√≠tmica")
else:
    print("    ‚Üí Skewness >= 0.5: Distribuci√≥n moderadamente sesgada")
    print("    ‚Üí Transformaci√≥n logar√≠tmica podr√≠a ser beneficiosa")


# --- Comparaci√≥n con correlaciones ---
print("\n" + "="*60)
print("IMPACTO EN CORRELACIONES")
print("="*60)

# Crear DataFrame con Fare transformado
df_compare = df[['Age', 'Fare', 'Pclass', 'Survived']].dropna()
df_compare_log = df_compare.copy()
df_compare_log['Fare_Log10'] = np.log10(df_compare_log['Fare'].replace(0, 0.01))  # Evitar log(0)

print("\n--- Correlaci√≥n con 'Survived' ---")
print(f"  Fare (Original):     {df_compare['Fare'].corr(df_compare['Survived']):.4f}")
print(f"  Fare_Log10:          {df_compare_log['Fare_Log10'].corr(df_compare_log['Survived']):.4f}")
print(f"\n--- Correlaci√≥n con 'Pclass' ---")
print(f"  Fare (Original):     {df_compare['Fare'].corr(df_compare['Pclass']):.4f}")
print(f"  Fare_Log10:          {df_compare_log['Fare_Log10'].corr(df_compare_log['Pclass']):.4f}")


