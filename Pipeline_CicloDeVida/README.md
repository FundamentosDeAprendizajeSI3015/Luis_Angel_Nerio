#  Pipeline de Ciclo de Vida de Datos - Machine Learning

Un pipeline completo y profesional para **anÃ¡lisis exploratorio, limpieza, transformaciÃ³n y preparaciÃ³n de datos** para proyectos de machine learning. 

Este proyecto implementa un flujo automatizado que toma un CSV crudo y lo transforma en datasets listos para entrenamiento, generando reportes estadÃ­sticos y visualizaciones en el proceso.

---

##  Â¿QuÃ© hace este pipeline?

El pipeline ejecuta **6 etapas principales** de forma automÃ¡tica:

1. **Ingesta y Perfilado** â†’ Carga el CSV, valida integridad y genera resumen de caracterÃ­sticas
2. **AnÃ¡lisis Exploratorio (EDA)** â†’ EstadÃ­sticas, outliers, correlaciones, distribuciones
3. **Visualizaciones** â†’ Histogramas, scatter plots, box plots, heatmaps, PCA, t-SNE, UMAP
4. **Transformaciones** â†’ Feature engineering, transformaciÃ³n logarÃ­tmica, encoding (one-hot, label, binary)
5. **Preprocesamiento** â†’ NormalizaciÃ³n con StandardScaler, codificaciÃ³n de targets, limpieza
6. **GeneraciÃ³n de Reportes** â†’ JSON con anÃ¡lisis, grÃ¡ficos PNG y CSV procesados

### Salida del Pipeline

DespuÃ©s de ejecutar, obtendrÃ¡s:

```
reports/
â”œâ”€ results/
â”‚  â”œâ”€ eda_report.json               # AnÃ¡lisis estadÃ­stico completo
â”‚  â”œâ”€ transform_report.json         # Detalle de transformaciones
â”‚  â”œâ”€ stress_mapping.json           # Mapeo de variables categÃ³ricas
â”‚  â”œâ”€ data_overview.json            # Perfil del dataset original
â”‚  â””â”€ execution_log_TIMESTAMP.txt   # Log de ejecuciÃ³n
â”‚
â””â”€ figures/
   â”œâ”€ histogramas_todas_variables.png
   â”œâ”€ scatters_habitos_vs_gpa.png
   â”œâ”€ boxplots_por_stress.png
   â”œâ”€ corr_heatmap_pearson.png
   â”œâ”€ corr_heatmap_spearman.png
   â”œâ”€ pca_2d_gpa.png
   â”œâ”€ tsne_2d_gpa.png
   â””â”€ umap_2d_3d_gpa.html

data/processed/
â”œâ”€ dataset_transformado.csv         # Datos con transformaciones bÃ¡sicas
â”œâ”€ dataset_transformado_onehot.csv  # One-hot encoding
â”œâ”€ dataset_transformado_label.csv   # Label encoding
â”œâ”€ dataset_transformado_binary.csv  # Binary encoding
â””â”€ dataset_processed.csv            # Features normalizadas + targets
```

---

##  Requisitos

- **Python 3.9+**
- LibrerÃ­as listadas en `requirements.txt` (pandas, scikit-learn, matplotlib, plotly, umap-learn, etc.)

---
##  CÃ³mo ejecutar

### 1. PreparaciÃ³n (primera vez)

```bash
# Clonar o descargar el proyecto
cd Pipeline_CicloDeVida

# Instalar dependencias
pip install -r requirements.txt
```

### 2. Preparar los datos

Coloca tu archivo CSV en:
```
data/raw/tu_dataset.csv
```

El pipeline automÃ¡ticamente encontrarÃ¡ y cargarÃ¡ el primer CSV en esa carpeta.

### 3. Ejecutar el pipeline

```bash
python main.py
```

Eso es todo. El pipeline harÃ¡ el resto (ingesta â†’ EDA â†’ visualizaciones â†’ transformaciones â†’ preprocesamiento).

---

##  Estructura del Proyecto

```
Pipeline_CicloDeVida/
â”œâ”€ data/
â”‚  â”œâ”€ raw/                 # Coloca aquÃ­ tu CSV crudo
â”‚  â”œâ”€ interim/             # (Opcional) datos intermedios
â”‚  â””â”€ processed/           # Datasets transformados (generados automÃ¡ticamente)
â”‚
â”œâ”€ src/
â”‚  â”œâ”€ config.py            # ConfiguraciÃ³n centralizada (rutas, nombres de columnas)
â”‚  â”œâ”€ ingest.py            # Carga y validaciÃ³n inicial de datos
â”‚  â”œâ”€ eda.py               # AnÃ¡lisis exploratorio detallado
â”‚  â”œâ”€ visualize.py         # GeneraciÃ³n de 10+ visualizaciones
â”‚  â”œâ”€ preprocess.py        # Limpieza y normalizaciÃ³n
â”‚  â”œâ”€ transform.py         # Transformaciones y encodings
â”‚  â””â”€ utils.py             # Funciones auxiliares y logging
â”‚
â”œâ”€ reports/
â”‚  â”œâ”€ figures/             # GrÃ¡ficos PNG e HTML (generados automÃ¡ticamente)
â”‚  â””â”€ results/             # Reportes JSON y logs (generados automÃ¡ticamente)
â”‚
â”œâ”€ main.py                 # Punto de entrada (orquesta todo el flujo)
â”œâ”€ requirements.txt        # Dependencias del proyecto
â””â”€ README.md               # Este archivo
```

---

##  ConfiguraciÃ³n

Edita `src/config.py` para personalizar:

- **Rutas**: dÃ³nde buscar datos crudos, dÃ³nde guardar procesados
- **Nombres de columnas**: `COL_GPA`, `COL_STRESS`, `COL_HOURS` 
- **Rangos esperados**: lÃ­mites vÃ¡lidos para validaciones
- **Umbrales**: asimetrÃ­a para transformaciones logarÃ­tmicas, correlaciÃ³n mÃ­nima, etc.

### Ejemplo de adaptaciÃ³n a tu dataset:

```python
# src/config.py
COL_GPA = "tu_columna_gpa"           
COL_STRESS = "tu_columna_estres"     
COL_HOURS = {"hora_estudio", "hora_sueno", ...}  # Tus columnas de hÃ¡bitos
```

---

##  AnÃ¡lisis que genera

El pipeline calcula y documenta:

- **EstadÃ­sticas bÃ¡sicas**: media, mediana, moda, desv. estÃ¡ndar, varianza
- **Cuartiles e IQR**: para detecciÃ³n de outliers
- **Percentiles y deciles**: distribuciÃ³n de datos
- **AnÃ¡lisis de outliers**: cantidad, porcentaje, impacto de remociÃ³n
- **Correlaciones**: matrices Pearson y Spearman + pares altos
- **AsimetrÃ­as**: skewness de cada variable
- **Validaciones**: rangos esperados, valores Ãºnicos, identificaciÃ³n de anomalÃ­as

---

##  Visualizaciones incluidas

-  **Histogramas** (todas las variables con media/mediana)
-  **Scatter plots** (relaciones bivariadas)
-  **Box plots** (distribuciones y outliers)
-  **Heatmaps** (correlaciones Pearson y Spearman)
-  **ComparaciÃ³n outliers** (antes/despuÃ©s de remover)
- **PCA 2D** (reducciÃ³n de dimensionalidad)
-  **t-SNE 2D** (separaciÃ³n no-lineal)
-  **UMAP 2D/3D** (exploraciÃ³n interactiva en HTML)

---

##  Stack tecnolÃ³gico

| Componente | LibrerÃ­a |
|-----------|----------|
| Procesamiento de datos | pandas, numpy |
| EstadÃ­sticas | scipy |
| Machine Learning | scikit-learn |
| VisualizaciÃ³n | matplotlib, plotly |
| ReducciÃ³n dimensional | PCA, t-SNE, UMAP |
| Encoding | category_encoders |

---


---

##  Notas

- Todos los outputs se guardan automÃ¡ticamente con timestamps
- El log de ejecuciÃ³n captura todas las operaciones realizadas
- Maneja datasets con celdas vacÃ­as (NaN) de forma robusta
- Compatible con Windows, macOS y Linux

---

##  Autor

Luis Angel Nerio | Aprendizaje AutomÃ¡tico

---

**Â¡Listo! Tu pipeline estÃ¡ configurado y listo para analizar datos.** ğŸ‰
